{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba7fd6f9-e81c-4041-b826-3db7765850ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Cuaderno de Ingesta de datos\n",
    "\n",
    "En este bloque traeremos la información desde datos abiertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9f6405b-6fef-4b7c-b4be-aa4413e387a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Paso 1: Descargar los datos con requests y leerlos en pandas\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "url_secop = \"https://www.datos.gov.co/resource/rpmr-utcd.csv?$limit=100000\"\n",
    "url_men = \"https://www.datos.gov.co/resource/nudc-7mev.csv?$limit=100000\"\n",
    "\n",
    "# Descargar contenido\n",
    "response_secop = requests.get(url_secop)\n",
    "response_men = requests.get(url_men)\n",
    "\n",
    "# Convertir contenido a pandas usando StringIO\n",
    "df_secop_pd = pd.read_csv(StringIO(response_secop.text))\n",
    "df_men_pd = pd.read_csv(StringIO(response_men.text))\n",
    "\n",
    "# Convertir pandas a Spark\n",
    "df_secop = spark.createDataFrame(df_secop_pd)\n",
    "df_men = spark.createDataFrame(df_men_pd)\n",
    "\n",
    "# Mostrar en Databricks\n",
    "display(df_secop)\n",
    "display(df_men)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72033ee1-c243-4e48-aa22-460ba59e3a80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_secop_pd = df_secop.toPandas()\n",
    "df_men_pd = df_men.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0363bb0-99ae-40fa-b187-acef71d5c632",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Celda 2: Guardar los DataFrames como tablas Delta\n",
    "# La función .saveAsTable() guarda los datos y registra la tabla en el Unity Catalog.\n",
    "# El modo \"overwrite\" reemplaza la tabla si ya existe, ideal para actualizaciones.\n",
    "df_secop.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"main.diplomado_datos.secop\")\n",
    "df_men.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"main.diplomado_datos.men_estadisticas\")\n",
    "\n",
    "print(\"¡Tablas guardadas exitosamente en el catálogo 'main', esquema 'diplomado_datos'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e663c16d-87fa-40c4-8e26-01b495c3eb4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Paso 1: Descargar los datos con requests y leerlos en pandas\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "url_secop = \"https://www.datos.gov.co/resource/rpmr-utcd.csv?$limit=100000&$offset=100000\"\n",
    "\n",
    "# Descargar contenido\n",
    "response_secop = requests.get(url_secop)\n",
    "\n",
    "# Convertir contenido a pandas usando StringIO\n",
    "df_secop_pd = pd.read_csv(StringIO(response_secop.text), delimiter=',', header=0)\n",
    "\n",
    "# Convertir pandas a Spark\n",
    "df_secop = spark.createDataFrame(df_secop_pd)\n",
    "\n",
    "# Mostrar en Databricks\n",
    "display(df_secop)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d4580df-0fcd-463f-b924-57550d462bb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_secop.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"main.diplomado_datos.secop\")\n",
    "df_men.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"main.diplomado_datos.men_estadisticas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0146f3d3-6b88-40e3-aba7-169d3d1e2bff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "\n",
    "target_schema = spark.table(\"main.diplomado_datos.secop\").schema\n",
    "\n",
    "df_secop_aligned = df_secop.select(\n",
    "    [col(field.name).cast(field.dataType) for field in target_schema.fields]\n",
    ")\n",
    "\n",
    "\n",
    "df_secop_aligned.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"main.diplomado_datos.secop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d146217e-24d8-43fd-9633-384e4e81b048",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# descarga de datos en bloques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "866932ef-3cd1-4b82-b9fc-6a88477a1972",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total_registros = 19446266\n",
    "offset_inicial = 200000\n",
    "limite = 100000\n",
    "paginas_faltantes = ((total_registros - offset_inicial) // limite) + 1\n",
    "\n",
    "print(f\"Quedan {paginas_faltantes} bloques por descargar...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "360bd3dc-a68f-441e-8900-8774c61c71b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, lit\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "def descargar_guardar_secop(offset_inicial, limite, total_registros, tabla_destino):\n",
    "    \"\"\"\n",
    "    Descarga y guarda bloques de datos del SECOP en una tabla Delta de Databricks.\n",
    "    \n",
    "    Args:\n",
    "        offset_inicial (int): Offset desde el cual empezar la descarga.\n",
    "        limite (int): Cantidad de filas por bloque.\n",
    "        total_registros (int): Total estimado de registros a descargar.\n",
    "        tabla_destino (str): Nombre completo de la tabla Delta (ej: \"main.diplomado_datos.secop\").\n",
    "    \"\"\"\n",
    "\n",
    "    paginas_faltantes = ((total_registros - offset_inicial) // limite) + 1\n",
    "    print(f\"🔁 Descargando {paginas_faltantes} bloques desde offset {offset_inicial}...\")\n",
    "\n",
    "    invalid_values = [\"NO DEFINIDO\", \"NO APLICA\", \"N/A\", \"SIN DATO\", \"NULL\", \"S/I\", \"\", \"NO_REGISTRA\"]\n",
    "\n",
    "    for i in range(paginas_faltantes):\n",
    "        offset = offset_inicial + (i * limite)\n",
    "        url = f\"https://www.datos.gov.co/resource/rpmr-utcd.csv?$limit={limite}&$offset={offset}\"\n",
    "\n",
    "        print(f\"⬇️  Página {i+1}/{paginas_faltantes} - Offset: {offset}\")\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            df_secop_pd = pd.read_csv(\n",
    "                StringIO(response.text),\n",
    "                dtype=str,\n",
    "                low_memory=False\n",
    "            )\n",
    "\n",
    "            if not df_secop_pd.empty:\n",
    "                df_secop = spark.createDataFrame(df_secop_pd)\n",
    "\n",
    "                # Obtener el schema objetivo de la tabla Delta\n",
    "                target_schema = spark.table(tabla_destino).schema\n",
    "                df_secop_aligned = df_secop\n",
    "\n",
    "                # Alinear columnas usando try_cast para evitar errores de tipo\n",
    "                for field in target_schema.fields:\n",
    "                    col_name = field.name\n",
    "                    data_type = field.dataType.simpleString()  # ejemplo: \"bigint\", \"double\", \"string\"\n",
    "\n",
    "                    if col_name in df_secop.columns:\n",
    "                        if data_type.startswith(\"bigint\") or data_type.startswith(\"int\"):\n",
    "                            df_secop_aligned = df_secop_aligned.withColumn(\n",
    "                                col_name,\n",
    "                                expr(f\"try_cast({col_name} AS bigint)\")\n",
    "                            )\n",
    "                        elif data_type.startswith(\"double\") or data_type.startswith(\"float\") or data_type.startswith(\"decimal\"):\n",
    "                            df_secop_aligned = df_secop_aligned.withColumn(\n",
    "                                col_name,\n",
    "                                expr(f\"try_cast({col_name} AS double)\")\n",
    "                            )\n",
    "                        else:\n",
    "                            df_secop_aligned = df_secop_aligned.withColumn(\n",
    "                                col_name,\n",
    "                                col(col_name).cast(field.dataType)\n",
    "                            )\n",
    "                    else:\n",
    "                        df_secop_aligned = df_secop_aligned.withColumn(\n",
    "                            col_name, lit(None).cast(field.dataType)\n",
    "                        )\n",
    "\n",
    "                # Escribir en la Delta Table\n",
    "                df_secop_aligned.write.format(\"delta\") \\\n",
    "                    .mode(\"append\") \\\n",
    "                    .option(\"mergeSchema\", \"true\") \\\n",
    "                    .saveAsTable(tabla_destino)\n",
    "\n",
    "                print(f\"✅ Página {i+1} almacenada con {df_secop_pd.shape[0]} filas\")\n",
    "            else:\n",
    "                print(f\"⚠️ Página {i+1} llegó vacía. Terminando descarga.\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"❌ Error HTTP {response.status_code} en página {i+1}.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "420e16ce-8aca-4a4d-8487-1588a158dfc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Parámetros de entrada\n",
    "offset_inicial = 200000  # O el último offset que cargaste\n",
    "limite = 100000\n",
    "total_registros = 19446266\n",
    "tabla_destino = \"main.diplomado_datos.secop\"\n",
    "\n",
    "# Ejecutar función\n",
    "descargar_guardar_secop(offset_inicial, limite, total_registros, tabla_destino)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5035440133904189,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Ingesta_Datos_Abiertos",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
